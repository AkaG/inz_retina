{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from neural_network.nn_manager.TrainManager import TrainManager\n",
    "from neural_network.store.DBNNSave import DBNNSave\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Reshape, Input, Conv2D, BatchNormalization\n",
    "from keras.layers.convolutional import Convolution1D, Convolution2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras.backend as K\n",
    "from random import shuffle\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = tf.Session(config=config)\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDetectionNN(TrainManager):\n",
    "    def __init__(self):\n",
    "        self.path_to_data = './sd-size-50.hdf5'\n",
    "        self.prepare_data(self.path_to_data)\n",
    "        self.batch_size = 32\n",
    "        self.epochs = 20\n",
    "        super(SequenceDetectionNN, self).__init__()\n",
    "        \n",
    "        self.datagen_train = ImageDataGenerator(\n",
    "            vertical_flip=True,\n",
    "            zoom_range=0.2,\n",
    "            shear_range=0.2\n",
    "            horizontal_flip=True,\n",
    "            rotation_range = 30\n",
    "        )\n",
    "        \n",
    "        self.datagen_val = ImageDataGenerator(\n",
    "        )\n",
    "        \n",
    "    def prepare_data(self, path):\n",
    "        hdf5_file = h5py.File(path, 'r')\n",
    "        self.get_handlers(hdf5_file)\n",
    "        self.load_sizes()\n",
    "        \n",
    "    def load_sizes(self):\n",
    "        self.img_size_1 = self.X_train.shape[1]\n",
    "        self.img_size_2 = self.X_train.shape[2]\n",
    "        self.outputs_size = self.Y_train.shape[1]\n",
    "        self.num_train_samples = self.X_train.shape[0]\n",
    "        self.num_val_samples = self.X_val.shape[0]\n",
    "    \n",
    "    def get_handlers(self, file):\n",
    "        self.X_train = file['train_data_x']\n",
    "        self.Y_train = file['train_data_y']\n",
    "        self.X_val = file['val_data_x']\n",
    "        self.Y_val = file['val_data_y']\n",
    "    \n",
    "    def store_method(self):\n",
    "        return DBNNSave()\n",
    "\n",
    "    def train_data_generator(self):\n",
    "        generator = self._generator(self.X_train, self.Y_train, self.datagen_train)\n",
    "        return generator\n",
    "\n",
    "    def test_data_generator(self):\n",
    "        generator = self._generator(self.X_val, self.Y_val, self.datagen_val)\n",
    "        return generator\n",
    "        \n",
    "    def store_method(self):\n",
    "        return DBNNSave()\n",
    "\n",
    "    def create_model(self):\n",
    "        input_image = Input(shape=(self.img_size_1, self.img_size_2, 2))\n",
    "\n",
    "        layer = Conv2D(filters=32, kernel_size=(3, 3))(input_image)\n",
    "        layer = BatchNormalization(axis=1)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = MaxPooling2D(pool_size=(2, 2))(layer)\n",
    "        \n",
    "        layer = Conv2D(filters=32, kernel_size=(3, 3))(layer)\n",
    "        layer = BatchNormalization(axis=1)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = MaxPooling2D(pool_size=(2, 2))(layer)\n",
    "        \n",
    "        layer = Conv2D(filters=32, kernel_size=(3, 3))(layer)\n",
    "        layer = BatchNormalization(axis=1)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "        layer = MaxPooling2D(pool_size=(2, 2))(layer)\n",
    "        \n",
    "        layer = Flatten()(layer)\n",
    "        \n",
    "        layer = Dense(1024)(layer)\n",
    "        layer = BatchNormalization(axis=1)(layer)\n",
    "        layer = Activation('relu')(layer)\n",
    "\n",
    "        layer = Dense(1)(layer)\n",
    "        layer = BatchNormalization(axis=1)(layer)\n",
    "        output_layer = Activation('sigmoid')(layer)\n",
    "        model = Model(inputs=input_image, outputs=output_layer)\n",
    "        model.compile( optimizer='adam',\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy'])\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def _generator(self,X,Y,datagen):\n",
    "        batches = datagen.flow(X,Y, batch_size=self.batch_size, shuffle=False)\n",
    "        while 1:\n",
    "             for batch in batches:\n",
    "                yield batch\n",
    "        \n",
    "    def train(self):\n",
    "        self.train_model(\n",
    "            self.num_train_samples // self.batch_size,\n",
    "            self.num_val_samples // self.batch_size,\n",
    "            epochs=self.epochs\n",
    "        )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sd = SequenceDetectionNN()\n",
    "sd.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
