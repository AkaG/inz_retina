{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from text_processing.NGramCounter import NGramCounter\n",
    "from text_processing.NGramVectorBuilder import NGramVectorBuilder\n",
    "from data_module.models import Person, Examination, Description, ImageSeries\n",
    "from data_module.models import Image as Retina_Image\n",
    "from random import shuffle\n",
    "import random, re, PIL, csv, cv2, os, time\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "np.random.seed(7)\n",
    "import h5py\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_preparer():\n",
    "    def __init__(self):\n",
    "        self.load_image_resolution()\n",
    "    \n",
    "    def samples_from_file(self, f):\n",
    "            reader = csv.reader(f.readline().split('\\n'), delimiter=',')\n",
    "            for row in reader:\n",
    "                train_samples = np.array(row[:-1],dtype='uint8')\n",
    "                break\n",
    "\n",
    "            reader = csv.reader(f.readline().split('\\n'), delimiter=',')\n",
    "            for row in reader:\n",
    "                val_samples = np.array(row[:-1],dtype='uint8')\n",
    "                break\n",
    "\n",
    "            reader = csv.reader(f.readline().split('\\n'), delimiter=',')\n",
    "            for row in reader:\n",
    "                test_samples = np.array(row[:-1],dtype='uint8')\n",
    "                break\n",
    "            f.close()\n",
    "            return train_samples,val_samples,test_samples\n",
    "    \n",
    "    def get_ngram_vector_builder(self):\n",
    "        n = 2; self.outputs = 1000; limit = 0\n",
    "        ngc = NGramCounter()\n",
    "        self.n_gram = ngc.get_n_gram_histogram(n,limit,self.outputs)\n",
    "        return NGramVectorBuilder(self.n_gram)\n",
    "    \n",
    "    def load_image_resolution(self):\n",
    "        width = 1388\n",
    "        height = 1038\n",
    "        \n",
    "        self.img_size_2 = 100\n",
    "        self.img_size_1 = int(self.img_size_2 * (height / width))\n",
    "\n",
    "    def get_images_metadata(self,examinations):\n",
    "            metadata = []\n",
    "            for exam_id in examinations:\n",
    "                examination = Examination.objects.get(id=exam_id)\n",
    "                sequences = ImageSeries.objects.filter(examination_id=exam_id)\n",
    "                for i in range(len(sequences)):\n",
    "                    if sequences[i].name.endswith(\"after_registration\") or sequences[i].name.startswith(\"d\") : \n",
    "                        continue\n",
    "                    if sequences[i].name.startswith(\"left\"):\n",
    "                        side = 'L'\n",
    "                    else:\n",
    "                        side = 'R'\n",
    "                    imgModels = Retina_Image.objects.filter(image_series=sequences[i])\n",
    "                    imgNum = len(imgModels)\n",
    "                    if imgNum == 0:\n",
    "                        continue\n",
    "                    metadata.append({'examination_id':exam_id,'icd':examination.icd_code,'age': examination.current_age, 'sex':examination.person.sex  ,'side': side, 'series': sequences[i].id, 'first': imgModels[0].id, 'middle': imgModels[int(imgNum/2)].id,'last': imgModels[imgNum-1].id})\n",
    "                shuffle(metadata)\n",
    "            return metadata\n",
    "\n",
    "    def prepare_image(self,_id):\n",
    "        img = Retina_Image.objects.get(id=_id)\n",
    "        img = PIL.Image.open(img.image).convert('L')\n",
    "        arr_img = np.array(img)\n",
    "        arr_img = self.preprocess_image(arr_img, self.img_size_1, self.img_size_2)\n",
    "        return arr_img \n",
    "\n",
    "    def to_float(self,image):\n",
    "        func = np.vectorize(lambda x: x / 255.0)\n",
    "        return func(image)\n",
    "\n",
    "    def standardization(self,image):\n",
    "        return (image - np.mean(image)) / np.std(image)\n",
    "\n",
    "    def preprocess_image(self,image, size_1, size_2, channel=0):\n",
    "        image = resize(image, (self.img_size_1, self.img_size_2, 1))\n",
    "        image = self.to_float(image)\n",
    "        image = self.standardization(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "    def create_dataset_and_store(self,hdf5_file, name, metadata, encoded_ages):\n",
    "        x_name = name+'_x'\n",
    "        x_shape = (len(metadata), self.img_size_1, self.img_size_2, 3)\n",
    "        hdf5_file.create_dataset(x_name, x_shape, np.float32)\n",
    "        \n",
    "        medic_name = name+'_medic'\n",
    "        medic_shape = (len(metadata), 93)\n",
    "        hdf5_file.create_dataset(medic_name, medic_shape, np.float32)\n",
    "        \n",
    "        y_name = name+'_y'\n",
    "        y_shape = (len(metadata),9)\n",
    "        hdf5_file.create_dataset(y_name, y_shape, np.int8)\n",
    "        \n",
    "        meta_name = name+'_metadata'\n",
    "        meta_shape = (len(metadata),)\n",
    "        hdf5_file.create_group(meta_name)\n",
    "        \n",
    "        for i in range(len(metadata)):\n",
    "            meta_elem = metadata[i]\n",
    "\n",
    "            #save X data\n",
    "            img1 = self.prepare_image(meta_elem['first'])\n",
    "            img2 = self.prepare_image(meta_elem['middle'])\n",
    "            img3 = self.prepare_image(meta_elem['last'])\n",
    "\n",
    "            x = np.dstack((img1,img2,img3))\n",
    "            hdf5_file[x_name][i, ...] = x[None]\n",
    "            sex = [1, 0] #M\n",
    "            if meta_elem['sex'] == 'F':\n",
    "                sex = [0,1]\n",
    "            hdf5_file[medic_name][i, ...] = list(self.get_vector_age(encoded_ages,meta_elem['age'])) + sex\n",
    "\n",
    "            #save Y data\n",
    "            icds_vector = self.get_icd_encoded(self.onehot_encoded,self.label_encoder,meta_elem['icd'])\n",
    "            hdf5_file[y_name][i, ...] = icds_vector\n",
    "            \n",
    "            #save metadata\n",
    "            gr = hdf5_file.create_group(meta_name+'/'+str(i))\n",
    "            for k, v in meta_elem.items():\n",
    "                gr[k] = v\n",
    "                \n",
    "\n",
    "    def store_all_data_in_h5py_file(self):\n",
    "        \n",
    "        f = open('splited_data.txt')\n",
    "        train_samples, val_samples, test_samples = self.samples_from_file(f)\n",
    "\n",
    "        train_metadata = self.get_images_metadata(train_samples)\n",
    "        val_metadata = self.get_images_metadata(val_samples)\n",
    "        test_metadata = self.get_images_metadata(test_samples)\n",
    "\n",
    "        hdf5_path = './data_icd6.hdf5'\n",
    "        hdf5_file = h5py.File(hdf5_path, mode='w')\n",
    "        \n",
    "        ages = self.get_list_of_ages()\n",
    "        encoded_ages = to_categorical(ages)\n",
    "        \n",
    "        icds = self.get_list_of_icds()\n",
    "        values = icds\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        integer_encoded = label_encoder.fit_transform(values)\n",
    "        # binary encode\n",
    "        onehot_encoder = OneHotEncoder(sparse=False)\n",
    "        integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "        self.onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "        \n",
    "        self.create_dataset_and_store(hdf5_file,'train_data',train_metadata,encoded_ages)\n",
    "        self.create_dataset_and_store(hdf5_file,'val_data',val_metadata,encoded_ages)\n",
    "        self.create_dataset_and_store(hdf5_file,'test_data',test_metadata,encoded_ages)\n",
    "            \n",
    "        hdf5_file.close()\n",
    "\n",
    "    def get_list_of_ages(self):\n",
    "        ages = set()\n",
    "        for examin in Examination.objects.filter():\n",
    "            ages.add(examin.current_age)\n",
    "        return list(ages)\n",
    "    \n",
    "    def get_icd_encoded(self,onehot_encoded,lebel_encoder,icd):\n",
    "        for el in range(len(onehot_encoded)):\n",
    "            inverted = label_encoder.inverse_transform([argmax(onehot_encoded[el, :])])\n",
    "            if inverted == icd:\n",
    "                return onehot_encoded[el]\n",
    "            \n",
    "    def get_list_of_icds(self):\n",
    "        icds = set()\n",
    "        for examin in Examination.objects.filter():\n",
    "            icds.add(examin.icd_code)\n",
    "        return list(icds)\n",
    "    \n",
    "    def get_vector_age(self,encoded, age):\n",
    "        for el in encoded:\n",
    "            if argmax(el) == age:\n",
    "                return el\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adam\\AppData\\Local\\conda\\conda\\envs\\inz_retina\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "data_preparer = Data_preparer()\n",
    "data_preparer.store_all_data_in_h5py_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['h 35.0', 'h 35.3', 'h 57', 'h 31.8', 'h 32', 'h 52.1', 'h 34', 'd 31', 'h 30']\n",
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "from numpy import argmax\n",
    "def get_list_of_icds():\n",
    "    icds = set()\n",
    "    arr = []\n",
    "    for examin in Examination.objects.filter():\n",
    "        icds.add(examin.icd_code)\n",
    "        arr.append(examin.icd_code)\n",
    "    return list(icds)\n",
    "\n",
    "icds = get_list_of_icds()\n",
    "print(icds)\n",
    "from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "values = icds\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(values)\n",
    "# binary encode\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "    \n",
    "def get_icd_encoded(onehot_encoded,lebel_encoder,icd):\n",
    "    for el in range(len(onehot_encoded)):\n",
    "        inverted = label_encoder.inverse_transform([argmax(onehot_encoded[el, :])])\n",
    "        if inverted == icd:\n",
    "            return onehot_encoded[el]\n",
    "\n",
    "c = get_icd_encoded(onehot_encoded,label_encoder,'d 31')\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'arr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-e3eb363b4781>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'arr' is not defined"
     ]
    }
   ],
   "source": [
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-7f5a38cfc141>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# one hot encode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mencoded_ages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mages\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_vector_age\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mencoded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ages' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "# one hot encode\n",
    "encoded_ages = to_categorical(ages)\n",
    "def get_vector_age(encoded, age):\n",
    "    for el in encoded:\n",
    "        if argmax(el) == age:\n",
    "            return el\n",
    "v = list(get_vector_age(encoded_ages,20))\n",
    "m = v + [0,1]\n",
    "print(m)\n",
    "print(len(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'roc_curve' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-b0226fa72fe6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'roc_curve' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
