{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from text_processing.NGramCounter import NGramCounter\n",
    "from text_processing.NGramVectorBuilder import NGramVectorBuilder\n",
    "from data_module.models import Person, Examination, Description, ImageSeries\n",
    "from data_module.models import Image as Retina_Image\n",
    "from random import shuffle\n",
    "import random, re, PIL, csv, cv2, os, time, sys\n",
    "import numpy as np\n",
    "from skimage.transform import resize\n",
    "np.random.seed(7)\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_preparer():\n",
    "    def __init__(self):\n",
    "        self.load_image_resolution()\n",
    "    \n",
    "    def samples_from_file(self, f):\n",
    "            reader = csv.reader(f.readline().split('\\n'), delimiter=',')\n",
    "            for row in reader:\n",
    "                train_samples = np.array(row[:-1],dtype='uint8')\n",
    "                break\n",
    "\n",
    "            reader = csv.reader(f.readline().split('\\n'), delimiter=',')\n",
    "            for row in reader:\n",
    "                val_samples = np.array(row[:-1],dtype='uint8')\n",
    "                break\n",
    "\n",
    "            reader = csv.reader(f.readline().split('\\n'), delimiter=',')\n",
    "            for row in reader:\n",
    "                test_samples = np.array(row[:-1],dtype='uint8')\n",
    "                break\n",
    "            f.close()\n",
    "            return train_samples,val_samples,test_samples\n",
    "    \n",
    "    def load_image_resolution(self):\n",
    "        width = 1388\n",
    "        height = 1038\n",
    "        \n",
    "        self.img_size_2 = 150\n",
    "        self.img_size_1 = int(self.img_size_2 * (height / width))\n",
    "\n",
    "    def get_images_metadata(self, examinations):\n",
    "        pairs = []\n",
    "        for examin in examinations:\n",
    "            sequences = ImageSeries.objects.filter(examination=examin)\n",
    "            for i in range(len(sequences)):\n",
    "                if sequences[i].name.endswith(\"after_registration\"):\n",
    "                    continue\n",
    "                imgModels = Retina_Image.objects.filter(image_series=sequences[i])\n",
    "                for j in range(len(imgModels)):\n",
    "                    for k in range(len(imgModels)):\n",
    "                        if j >= k:\n",
    "                            continue\n",
    "                                \n",
    "                        number1 = int(re.search(r'\\d+', imgModels[j].name).group())\n",
    "                        number2 = int(re.search(r'\\d+', imgModels[k].name).group())\n",
    "                        result = number1 > number2\n",
    "                        y_train = 1\n",
    "                        if (result):\n",
    "                            y_train = 0\n",
    "                        pairs.append(\n",
    "                            {'series': sequences[i].id, 'first': imgModels[k].id, 'second': imgModels[j].id,\n",
    "                                'y_train': y_train, 'first_name': imgModels[k].name, 'second_name': imgModels[j].name})\n",
    "                        pairs.append(\n",
    "                            {'series': sequences[i].id, 'first': imgModels[j].id, 'second': imgModels[k].id,\n",
    "                                'y_train': 1-y_train, 'first_name': imgModels[j].name, 'second_name': imgModels[k].name})\n",
    "        shuffle(pairs)\n",
    "        return pairs\n",
    "                            \n",
    "\n",
    "    def prepare_image(self,_id):\n",
    "        img = Retina_Image.objects.get(id=_id)\n",
    "        img = PIL.Image.open(img.image).convert('L')\n",
    "        arr_img = self.preprocess_image(img)\n",
    "        return arr_img \n",
    "\n",
    "    def standardization(self,image):\n",
    "        return (image - np.mean(image)) / np.std(image)\n",
    "    \n",
    "    def to_float(self, image):\n",
    "        func = np.vectorize(lambda x: x / 255.0)\n",
    "        return func(image)\n",
    "    \n",
    "    def preprocess_image(self,image):\n",
    "        image = np.array(image)\n",
    "        image = self.standardization(image)\n",
    "        image = resize(image, (self.img_size_1, self.img_size_2, 1))\n",
    "        return image\n",
    "\n",
    "    def create_dataset_and_store(self,hdf5_file, name, metadata):\n",
    "        x_name = name+'_x'\n",
    "        x_shape = (len(metadata), self.img_size_1, self.img_size_2,2)\n",
    "        hdf5_file.create_dataset(x_name, x_shape, np.float32)\n",
    "        \n",
    "        y_name = name+'_y'\n",
    "        y_shape = (len(metadata),1)\n",
    "        hdf5_file.create_dataset(y_name, y_shape, np.int8)\n",
    "        \n",
    "        meta_name = name+'_metadata'\n",
    "        meta_shape = (len(metadata),)\n",
    "        hdf5_file.create_group(meta_name)\n",
    "        self.cache = dict()\n",
    "        for i in range(len(metadata)):\n",
    "            meta_elem = metadata[i]\n",
    "\n",
    "            #save X data\n",
    "            id_img_1 = meta_elem['first']\n",
    "            id_img_2 = meta_elem['second']\n",
    "            \n",
    "            prepared_img_1 = self.get_cached_image(id_img_1)\n",
    "            prepared_img_2 = self.get_cached_image(id_img_2)\n",
    "                \n",
    "            x = np.dstack((prepared_img_1,prepared_img_2))\n",
    "            hdf5_file[x_name][i, ...] = x[None]\n",
    "\n",
    "            #save Y data\n",
    "            hdf5_file[y_name][i, ...] = meta_elem['y_train']\n",
    "            \n",
    "            #save metadata\n",
    "            gr = hdf5_file.create_group(meta_name+'/'+str(i))\n",
    "            for k, v in meta_elem.items():\n",
    "                    gr[k] = v\n",
    "                \n",
    "    def get_cached_image(self,id_img):\n",
    "        if id_img not in self.cache:\n",
    "            self.cache[id_img] = self.prepare_image(id_img)\n",
    "        return self.cache[id_img]\n",
    "                \n",
    "                \n",
    "    def store_all_data_in_h5py_file(self):\n",
    "        \n",
    "        f = open('splited_data.txt')\n",
    "        train_samples, val_samples, test_samples = self.samples_from_file(f)\n",
    "\n",
    "        train_metadata = self.get_images_metadata(train_samples)\n",
    "        val_metadata = self.get_images_metadata(val_samples)\n",
    "        test_metadata = self.get_images_metadata(test_samples)\n",
    "\n",
    "        hdf5_path = './sd-size-150.hdf5'\n",
    "        hdf5_file = h5py.File(hdf5_path, mode='w')\n",
    "        \n",
    "        try: \n",
    "            self.create_dataset_and_store(hdf5_file,'train_data',train_metadata)\n",
    "            self.create_dataset_and_store(hdf5_file,'val_data',val_metadata)\n",
    "            self.create_dataset_and_store(hdf5_file,'test_data',test_metadata)\n",
    "            hdf5_file.close()\n",
    "            print('success')\n",
    "\n",
    "        except:\n",
    "            print('fail')\n",
    "            hdf5_file.close()\n",
    "            os.remove(hdf5_path)\n",
    "            raise\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adam\\AppData\\Local\\conda\\conda\\envs\\inz_retina\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "data_preparer = Data_preparer()\n",
    "data_preparer.store_all_data_in_h5py_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
